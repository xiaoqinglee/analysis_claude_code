# v5: コンテキスト圧縮

**コアの洞察: 忘れることは欠陥ではなく、能力である。**

v0-v4には暗黙の前提がある：対話履歴は無限に伸ばせる。現実はそうではない。

## 問題

```
200K tokenのコンテキストウィンドウ:
  [システムプロンプト]     ~2K tokens
  [CLAUDE.md]             ~3K tokens
  [ツール定義]             ~8K tokens
  [対話履歴]               増え続ける...
  [第50回ツール呼び出し]   -> 約180K tokens
  [第60回ツール呼び出し]   -> 200K超過、リクエスト失敗
```

複雑なリファクタリングは100回以上のツール呼び出しが必要になる場合がある。圧縮なしでは、エージェントは壁にぶつかる。

## 三層圧縮パイプライン

一種類の圧縮ではなく、三段階の構造:

```
毎エージェントターン:
+------------------+
| ツール呼び出し結果 |
+------------------+
        |
        v
[レイヤー1: マイクロ圧縮]       (サイレント、毎ターン)
最近3つのツール結果を保持。
古い結果を置換:
"[Old tool result content cleared]"
推定節約量 >= MIN_SAVINGS (20000 tokens) の場合のみクリア。
        |
        v
[チェック: tokens > threshold?]  threshold = ctx_window - output_reserve - 13000
        |
   no --+-- yes
   |         |
   v         v
続行    [レイヤー2: 自動圧縮]          (上限付近)
        対話全体を要約に圧縮。
        全メッセージを置換（保持なし）。
        最近5ファイルを復元。
                |
                v
        [レイヤー3: 手動圧縮]          (ユーザー /compact)
        ユーザー指示に沿った圧縮。
        同じ仕組み、カスタムプロンプト。

全工程: 完全な記録をディスクに保存 (JSONL)。
```

| レイヤー | トリガー | 動作 | ユーザー体験 |
|----------|----------|------|-------------|
| マイクロ圧縮 | 毎ターン自動 | 古いツール出力をクリア | 無感知 |
| 自動圧縮 | 上限付近 | 対話全体を要約に圧縮 | 通知表示 |
| 手動圧縮 | `/compact` コマンド | ユーザー指示に沿った圧縮 | 主体的に実行 |

## 動的閾値

自動圧縮の閾値は固定定数ではなく、モデルの実際の制限から動的に計算される:

```python
def auto_compact_threshold(context_window=200000, max_output=16384):
    """threshold = context_window - min(max_output, 20000) - 13000"""
    output_reserve = min(max_output, 20000)
    return context_window - output_reserve - 13000
    # 200Kウィンドウ: 200000 - 16384 - 13000 = 170616
```

13000のバッファはシステムプロンプト、ツール定義、オーバーヘッドを考慮。`min(max_output, 20000)` のキャップにより、max_outputが大きいモデルでの過早な圧縮トリガーを防ぐ。

## should_compact: 閾値チェック

`should_compact` は総トークン数が閾値を超えたかのみをチェックする:

```python
def should_compact(self, messages):
    total = sum(self.estimate_tokens(json.dumps(m, default=str)) for m in messages)
    return total > self.TOKEN_THRESHOLD
```

追加の収益保護はない。収益保護はマイクロ圧縮で実装されている（下記参照）。

## マイクロ圧縮: サイレントクリーニング

毎ターン、古い大型ツール出力をプレースホルダーに置換。最近のものは保持:

```python
COMPACTABLE_TOOLS = {"bash", "read_file", "write_file", "edit_file", "glob", "grep", "list_dir", "notebook_edit"}
KEEP_RECENT = 3

def microcompact(messages):
    """古い大型ツール結果をプレースホルダーに置換"""
    tool_results = find_tool_results(messages, COMPACTABLE_TOOLS)
    to_compact = tool_results[:-KEEP_RECENT]

    # 推定総節約量を計算し、MIN_SAVINGS (20000) 未満ならスキップ
    estimated_savings = sum(estimate_tokens(block) for block in to_compact if estimate_tokens(block) > 1000)
    if estimated_savings >= MIN_SAVINGS:
        for result in to_compact:
            if estimate_tokens(result) > 1000:
                result["content"] = "[Old tool result content cleared]"

    return messages
```

重要な点: **内容**のみクリアし、ツール呼び出しの構造は保持する。モデルは何を呼び出したか知っている。古い出力が見えないだけで、必要なら再度読めばいい。推定節約量 >= MIN_SAVINGS（20000 tokens、cli.js zUY=20000と一致）の場合のみクリアを実行する。

## トークン推定

cli.jsの文字数ベースの式でトークン数を推定:

```python
@staticmethod
def estimate_tokens(text: str) -> int:
    # cli.js H2: Math.round(A.length / q), デフォルト除数 q=4
    return len(text) // 4
```

約4文字で1トークン。cli.jsの実際の計算式と一致する。

## 自動圧縮閾値

閾値は固定パーセンテージではなく、数式で動的に計算される:

```python
def auto_compact_threshold(context_window=200000, max_output=16384):
    output_reserve = min(max_output, 20000)
    return context_window - output_reserve - 13000
    # 200Kウィンドウ: 200000 - 16384 - 13000 = 170616 (85.3%)
```

注意: Claude Codeは各ターン境界でmtime比較により外部ファイルの変更を検出する。
リアルタイムのファイルウォッチャーではない。変更は次のモデルターン開始時に感知される。

本番環境では各モデルターン前に28種類のアタッチメントタイプを並列計算する
（changed files、todoリマインダー、チームコンテキストなど）。
すべて `<system-reminder>` タグで包まれる。
簡略版ではmicrocompactとauto-compactでコアパターンを教える。

## 自動圧縮: 全メッセージを置換

コンテキストが動的閾値を超えた場合にトリガー。本番 cli.js の auto_compact は全メッセージリストを置換する。「最近N件を保持」する動作はない:

```python
def auto_compact(messages):
    # 1. 完全な記録をディスクに保存（データは失われない）
    save_transcript(messages)

    # 2. 圧縮前に最近読んだファイルをキャプチャ
    restored_files = restore_recent_files(messages)

    # 3. モデルで要約を生成
    summary = client.messages.create(
        model=MODEL,
        system="You are a conversation summarizer. Be concise but thorough.",
        messages=[{"role": "user", "content": "Summarize this conversation..."}],
        max_tokens=2000,
    ).content[0].text

    # 4. 全メッセージを要約で置換（最近N件の保持なし）
    result = [
        {"role": "user", "content": f"[Conversation compressed]\n\n{summary}"},
        {"role": "assistant", "content": "Understood. I have the context from the compressed conversation. Continuing work."},
    ]
    # ファイル内容を復元
    for rf in restored_files:
        result.append(rf)
        result.append({"role": "assistant", "content": "Noted, file content restored."})
    return result
```

**重要な設計**: 要約は対話履歴（userメッセージ）に注入。システムプロンプトは変更しない。これによりシステムプロンプトのprompt cacheが常に有効。

## 圧縮後のファイル復元

圧縮後、最近読んだファイルをコンテキストに復元し、再読み込みを不要にする:

```python
MAX_RESTORE_FILES = 5
MAX_RESTORE_TOKENS_PER_FILE = 5000
MAX_RESTORE_TOKENS_TOTAL = 50000

def restore_recent_files(messages):
    """メッセージからread_file呼び出しをスキャンし、最近のものを復元"""
    # メッセージを逆順に走査、ユニークなファイルパスを収集
    # 各ファイルを読み取り、MAX_RESTORE_TOKENS_PER_FILEまで切り詰め
    # MAX_RESTORE_FILESまたはMAX_RESTORE_TOKENS_TOTALに達したら停止
```

これにより、圧縮後もエージェントが最近作業していたファイルの認識を保持し、再読み込みが不要になる。

## 大型出力の降格

単一のツール出力が大きすぎる場合、ディスクに保存してプレビューを返す:

```python
def handle_tool_output(output):
    if estimate_tokens(output) > 40000:
        path = save_to_disk(output)
        return f"Output too large. Saved to: {path}\nPreview:\n{output[:2000]}..."
    return output
```

## サブエージェントも圧縮する

v3のサブエージェントは独立したコンテキストウィンドウを持ち、同様に圧縮を実行:

```python
def run_subagent(prompt, agent_type):
    sub_messages = [{"role": "user", "content": prompt}]

    while True:
        if should_compact(sub_messages):
            sub_messages = auto_compact(sub_messages)

        response = call_api(sub_messages)
        if response.stop_reason != "tool_use":
            break
        # ...

    return extract_final_text(response)
```

ディスク永続化の設計は後続の仕組みの基盤となる: 後の章で導入されるタスクシステムやマルチエージェント機構のデータはディスク上にあり、圧縮の影響を受けない。

## 比較

| 側面 | v4以前（圧縮なし） | v5（三層圧縮） |
|------|-------------------|----------------|
| 最大対話長 | コンテキストウィンドウに制限 | 理論上無限 |
| 長いタスクの信頼性 | コンテキスト溢れでクラッシュ | 優雅に降格 |
| 履歴データ | すべてメモリ内 | ディスク永続化 + メモリ要約 |
| 復旧能力 | なし | 要約または記録から復旧 |

## より深い洞察

> **人間の作業記憶にも限界がある。**

私たちは書いたすべてのコードを覚えているわけではない。「何をしたか、なぜしたか、現在の状態」を覚えている。圧縮はこの認知パターンを模倣する:

- マイクロ圧縮 = 短期記憶の自動減衰
- 全体圧縮 = 詳細記憶から概念記憶への転換
- ディスク記録 = 遡れる長期記憶

完全な記録は常にディスク上にある。圧縮が影響するのは作業記憶だけであり、アーカイブではない。

---

**コンテキストは有限、作業は無限。圧縮でエージェントは止まらない。**

[← v4](./v4-スキル機構.md) | [READMEに戻る](../README_ja.md) | [v6 →](./v6-タスクシステム.md)
